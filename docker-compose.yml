version: "3.3"
services:
  zookeeper:
    image: zookeeper:3.6.1
    container_name: zookeeper
    expose:
      - "2181"
    volumes:
      - kafka_zookeeper:/opt/zookeeper-3.6.1/data
    networks:
      kafkanet:
        ipv4_address: 172.25.0.11

  kafka1:
    image: wurstmeister/kafka:2.12-2.2.0
    container_name: kafka1
    command: [start-kafka.sh]
    expose:
      - "8080"
      - "9092"
    environment:
      KAFKA_ADVERTISED_HOST_NAME: 172.25.0.12
      KAFKA_ZOOKEEPER_CONNECT: 172.25.0.11:2181
      KAFKA_ADVERTISED_PORT: 9092
    volumes:
      - kafka_kafka1:/opt/kafka_2.12-2.2.0/logs
    depends_on:
      - "zookeeper"
    networks:
      kafkanet:
        ipv4_address: 172.25.0.12

  kafka2:
    image: wurstmeister/kafka:2.12-2.2.0
    container_name: kafka2
    command: [start-kafka.sh]
    expose:
      - "8080"
      - "9092"
    environment:
      KAFKA_ADVERTISED_HOST_NAME: 172.25.0.13
      KAFKA_ZOOKEEPER_CONNECT: 172.25.0.11:2181
      KAFKA_ADVERTISED_PORT: 9092
    volumes:
      - kafka_kafka2:/opt/kafka_2.12-2.2.0/logs
    depends_on:
      - "zookeeper"
    networks:
      kafkanet:
        ipv4_address: 172.25.0.13
  

  spark-master:
    image: cluster-apache-spark:3.0.2
    ports:
      - "6060:8080"
      - "7077:7077"
    volumes:
       - ./apps:/opt/spark-apps
       - ./data:/opt/spark-data
    environment:
      - SPARK_LOCAL_IP=spark-master
      - SPARK_WORKLOAD=master
    networks:
      kafkanet:
        ipv4_address: 172.25.0.14

  spark-worker-a:
    image: cluster-apache-spark:3.0.2
    ports:
      - "6061:8080"
      - "7000:7000"
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_DRIVER_MEMORY=1G
      - SPARK_EXECUTOR_MEMORY=1G
      - SPARK_WORKLOAD=worker
      - SPARK_LOCAL_IP=spark-worker-a
    volumes:
       - ./apps:/opt/spark-apps
       - ./data:/opt/spark-data
       
    networks:
      kafkanet:
        ipv4_address: 172.25.0.15
      
  spark-worker-b:
    image: cluster-apache-spark:3.0.2
    ports:
      - "6062:8080"
      - "7001:7000"
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_DRIVER_MEMORY=1G
      - SPARK_EXECUTOR_MEMORY=1G
      - SPARK_WORKLOAD=worker
      - SPARK_LOCAL_IP=spark-worker-b
    volumes:
        - ./apps:/opt/spark-apps
        - ./data:/opt/spark-data
    networks:
      kafkanet:
        ipv4_address: 172.25.0.16
  
  postgresql:
    image: postgres:latest
    container_name: postgresql
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: root
      POSTGRES_PASSWORD: root
      POSTGRES_DB: test
    volumes:
      - pgsql-data:/var/lib/postgresql/data
    networks:
      kafkanet:
        ipv4_address: 172.25.0.17
  
  pgadmin4:
    image: dpage/pgadmin4
    container_name: pgadmin4
    ports:
      - "5050:80"
    environment:
      PGADMIN_DEFAULT_EMAIL: gergpolsuklit1998@gmail.com
      PGADMIN_DEFAULT_PASSWORD: gergpol123
    networks:
      kafkanet:
        ipv4_address: 172.25.0.18

networks:
  kafkanet:
    name: kafkanet
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.25.0.0/24

volumes:
  kafka_zookeeper:
  kafka_kafka1:
  kafka_kafka2:
  pgsql-data:
  pgadmin-data: